{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3A 获取kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmer(seq, k):\n",
    "    kmer_list = [seq[i:i+k] for i in range(len(seq) - k + 1)]\n",
    "    return kmer_list\n",
    "\n",
    "# with open('rosalind_ba3a.txt') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     k = int(lines[0])\n",
    "#     seq = lines[1].strip()\n",
    "\n",
    "# for kmer in get_kmer(seq, k):\n",
    "#     print(kmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3B 有序kmers获取序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(kmer_list):\n",
    "    result = ''.join([kmer_list[i] if i == 0 else kmer_list[i][-1] for i in range(len(kmer_list))])\n",
    "    return result\n",
    "\n",
    "# with open('rosalind_ba3b.txt') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     lines = [line.strip() for line in lines]\n",
    "\n",
    "# print(get_seq(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3C 乱序kmer进行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_kmer(kmer_list):\n",
    "    result_dict = {}\n",
    "    for kmer in kmer_list:\n",
    "        for other_kmer in kmer_list:\n",
    "            if kmer[1:] == other_kmer[:-1]:\n",
    "                result_dict[kmer] = other_kmer\n",
    "                break\n",
    "            result_dict[kmer] = None\n",
    "    start_kmer = list(set(kmer_list) - set(result_dict.values()))[0]\n",
    "    flag = 1\n",
    "    start = start_kmer\n",
    "    while flag == 1:\n",
    "        print(f\"{start} -> {result_dict[start]}\")\n",
    "        if result_dict[result_dict[start]] != None:\n",
    "            start = result_dict[start]\n",
    "        else:\n",
    "            flag = 0\n",
    "\n",
    "# with open('rosalind_ba3c.txt') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     kmers = [line.strip() for line in lines]\n",
    "\n",
    "# pair_kmer(kmers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3D 根据序列绘制De_Bruijn_Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmer(seq, k):\n",
    "    kmer_list = [seq[i:i+k] for i in range(len(seq) - k + 1)]\n",
    "    return kmer_list\n",
    "\n",
    "def calculate_seq(seq):\n",
    "    dict = {'A':0, \"C\":1, \"G\":2, \"T\":3}\n",
    "    seq_trans = seq[::-1]\n",
    "    result = 0\n",
    "    for i in range(len(seq)):\n",
    "        result += (4**i)*dict[seq_trans[i]]\n",
    "    return result\n",
    "\n",
    "def De_Bruijn_Graph(seq, k):\n",
    "    kmer_list = get_kmer(seq, k)\n",
    "    result_dict = {}\n",
    "    for kmer in kmer_list:\n",
    "        pair1 = kmer[:-1]\n",
    "        pair2 = kmer[1:]\n",
    "        if pair1 in result_dict.keys():\n",
    "            result_dict[pair1].append(pair2)\n",
    "        else:\n",
    "            result_dict[pair1] = [pair2]\n",
    "    \n",
    "    keys = result_dict.keys()\n",
    "    keys_sorted = sorted(keys, key=lambda x: calculate_seq(x))\n",
    "    \n",
    "    for key in keys_sorted:\n",
    "        item = result_dict[key]\n",
    "        if len(item) > 1:\n",
    "            item = ','.join(item)\n",
    "        else:\n",
    "            item = item[0]\n",
    "        \n",
    "        print(f\"{key} -> {item}\")\n",
    "\n",
    "        \n",
    "\n",
    "# with open('rosalind_ba3d.txt') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     k = int(lines[0])\n",
    "#     seq = lines[1].strip()\n",
    "\n",
    "# De_Bruijn_Graph(seq, k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3E 根据kmers绘制De_Bruijn_Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def De_Bruijn_Graph(kmer_list):\n",
    "    result_dict = {}\n",
    "    for kmer in kmer_list:\n",
    "        pair1 = kmer[:-1]\n",
    "        pair2 = kmer[1:]\n",
    "        if pair1 in result_dict.keys():\n",
    "            result_dict[pair1].append(pair2)\n",
    "        else:\n",
    "            result_dict[pair1] = [pair2]\n",
    "    \n",
    "    keys = result_dict.keys()\n",
    "    keys_sorted = sorted(keys, key=lambda x: calculate_seq(x))\n",
    "    \n",
    "    for key in keys_sorted:\n",
    "        item = result_dict[key]\n",
    "        if len(item) > 1:\n",
    "            item = ','.join(item)\n",
    "        else:\n",
    "            item = item[0]\n",
    "        \n",
    "        print(f\"{key} -> {item}\")\n",
    "\n",
    "# with open('rosalind_ba3e.txt') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     kmers = [line.strip() for line in lines]\n",
    "\n",
    "# De_Bruijn_Graph(kmers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3F 欧拉环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114->1514->1513->1515->1114->1116->552->2686->2688->2766->2765->2764->2688->2687->552->18->82->83->84->575->574->576->84->907->974->975->1246->1248->1247->975->973->2858->2859->2857->973->907->909->908->84->18->81->80->237->235->541->875->874->1574->1575->1573->874->876->1302->1437->1679->1680->2540->2539->2541->1680->1678->1437->1435->1436->1302->1300->1301->876->541->1434->1433->1432->541->1662->1660->1661->541->543->1060->2935->2936->2937->1060->1062->1061->543->1524->1522->1523->543->542->235->374->2408->2409->2407->374->375->1985->1984->1986->375->1770->2099->2098->2100->2871->2870->2869->2100->1770->1768->1769->375->373->509->2284->2286->2285->509->510->1536->1534->1535->2800->2801->2802->1535->510->2009->2008->2010->2591->2590->2592->2010->510->508->668->2746->2748->2747->668->667->1780->1782->2261->2262->2260->1782->1831->1832->2209->2532->2530->2531->2209->2325->2552->2551->2553->2325->2324->2323->2987->2988->2986->2323->2209->2210->2211->1832->1833->1782->1781->667->669->508->540->539->2075->2076->2074->2846->2847->2845->2074->539->538->665->664->2641->2643->2642->664->666->2274->2273->2272->666->538->508->373->235->1274->1275->1273->235->236->332->333->2413->2414->2415->333->331->236->80->606->605->638->637->1464->1759->1760->1761->1464->1463->2220->2218->2219->1463->1462->637->639->902->901->903->639->605->604->80->79->1197->1195->1196->79->18->10->8->395->1627->2425->2426->2427->1627->1629->1628->1807->1841->1842->2466->2465->2464->1842->1840->1807->1809->1808->1628->2344->2346->2345->1628->395->394->396->8->5->15->91->92->93->241->1486->1488->1487->241->243->242->93->15->603->601->800->801->2079->2078->2077->801->799->601->611->612->610->943->944->945->2669->2668->2670->945->610->657->656->655->1160->1159->1161->655->610->601->602->15->288->1708->1709->1710->288->2150->2149->2151->288->286->287->1603->1605->1604->2034->2033->2032->2880->2878->2879->2032->1604->287->795->2709->2708->2707->795->2798->2799->2797->795->794->793->1746->1744->1745->793->287->15->2612->2613->2611->15->177->554->1067->1068->1066->554->555->553->758->934->936->935->758->2365->2366->2367->758->757->759->553->177->175->377->1776->1775->1774->2774->2775->2773->1774->377->378->2731->2733->2732->378->376->2120->2121->2119->376->175->2589->2587->2727->2962->2964->2963->2727->2725->2726->2587->2588->175->2131->2132->2133->175->176->996->1467->1465->1634->1635->1633->1465->1466->996->995->994->176->597->595->596->176->548->549->2354->2355->2933->2932->2934->2355->2353->549->547->938->1930->1932->1931->938->939->937->2189->2190->2188->937->547->176->2488->2490->2489->176->1789->1791->1790->2579->2580->2578->1790->176->15->1713->1712->1711->2451->2449->2450->1711->15->14->24->86->107->1131->1130->1129->1977->1976->1975->1129->107->108->221->293->904->2789->2790->2788->904->905->1707->1706->2193->2192->2191->1706->1705->1898->1899->1897->1705->905->906->293->2897->2896->2898->293->292->294->221->2526->2525->2524->221->2006->2115->2114->2113->2006->2005->2007->221->222->2169->2168->2167->222->220->108->106->202->464->465->463->202->204->1587->1585->2240->2241->2239->1585->1586->204->203->106->649->651->1519->2111->2112->2110->1519->1520->1521->2081->2082->2080->1521->651->650->1591->1593->1592->650->106->86->1453->1455->1454->1576->1577->1578->2537->2536->2538->1578->1454->86->85->87->150->867->865->866->150->834->832->833->150->149->148->1147->1149->1148->148->87->239->238->240->1431->1430->1429->1624->1625->1626->2710->2711->2712->1626->1429->240->87->24->351->2062->2064->2299->2301->2300->2064->2063->351->349->2305->2523->2522->2521->2305->2307->2306->349->350->24->348->768->767->766->348->2547->2545->2546->348->346->2162->2161->2684->2685->2683->2161->2163->346->347->1224->1223->1222->347->1124->1125->1123->347->24->23->1193->1194->1192->23->22->29->1023->1022->1893->1892->2978->2977->2979->1892->1891->1022->1021->29->30->77->1471->1473->2881->2883->2882->1473->1472->77->78->76->957->955->2153->2233->2235->2234->2153->2154->2152->955->956->76->30->28->178->593->592->594->1665->1663->1664->594->178->2884->2886->2885->178->2004->2003->2002->178->180->212->224->837->836->835->224->223->1064->1063->2051->2052->2050->1063->1065->1337->1336->1338->1065->223->225->212->213->699->910->912->911->699->697->698->213->321->345->537->536->535->345->343->1683->2042->2694->2693->2692->2042->2041->2043->1683->1681->1682->2438->2439->2437->1682->343->344->738->1441->1442->2913->2911->2912->1442->2456->2455->2457->1442->1443->738->2922->2921->2920->738->736->737->2348->2347->2349->737->344->321->320->915->1203->1991->1990->1992->1203->1201->1202->1504->1506->1505->1202->915->914->913->320->2890->2891->2892->320->319->213->284->2908->2909->2946->2944->2945->2909->2910->284->285->470->469->471->1821->1820->1819->471->285->283->213->211->180->179->295->1554->1553->1552->295->297->296->2230->2232->2231->296->179->1207->1208->1209->179->28->22->14->13->495->494->493->733->1070->1446->2899->2900->2901->1446->1444->1969->1970->1971->1444->1445->1070->1071->1069->733->735->1277->1276->1278->1828->1830->1829->2432->2431->2433->1829->1278->735->734->493->13->5->27->1319->1816->1817->1818->1319->1320->1318->27->197->467->466->917->968->969->967->917->916->918->466->468->197->2216->2215->2217->197->198->196->27->25->838->839->840->1389->1388->2199->2198->2197->1388->1387->840->25->32->57->947->948->946->57->184->741->1677->1675->1676->741->739->740->2172->2171->2170->740->184->429->428->427->1973->1974->1972->427->618->1479->2654->2653->2655->1479->1477->1478->618->617->1401->1399->1400->2178->2177->2176->1400->617->616->2454->2452->2453->616->427->184->1100->1101->1099->2020->2022->2021->1099->184->185->186->57->268->1561->1562->2251->2253->2252->1562->1563->268->269->1641->1639->1728->1726->1727->1639->1640->269->270->57->56->64->544->546->545->950->951->949->545->1055->1056->1177->1601->1602->1600->1177->1178->2925->2923->2924->1178->2266->2268->2267->1178->1179->1056->1054->545->1211->1210->1212->545->64->614->615->1041->1940->1941->1939->1041->1039->1040->615->613->1558->1560->1595->1596->1594->2434->2435->2436->1594->2386->2388->2387->1594->1560->1559->613->64->66->65->109->324->323->1725->1724->1723->1880->1881->1879->1723->323->322->109->2060->2568->2566->2567->2060->2061->2059->109->111->984->983->982->111->626->1597->1599->2848->2849->2850->1599->1598->626->625->627->111->110->65->401->400->402->2029->2030->2031->402->65->56->2792->2793->2791->56->2873->2872->2874->56->55->32->282->281->791->790->792->281->452->453->451->475->476->1346->1692->1691->1690->2914->2916->2915->1690->1346->1474->2716->2717->2718->1474->1475->1476->2277->2275->2276->1476->1346->1347->1345->476->477->797->796->798->477->451->281->280->988->2001->2000->1999->988->2202->2201->2200->988->990->1507->1509->1508->990->989->1307->1308->1306->989->280->703->2023->2025->2024->703->704->705->280->32->33->46->584->680->679->1948->1950->1949->679->681->584->585->631->633->647->660->659->658->2143->2144->2145->658->647->648->646->633->1837->1838->1839->633->632->585->1078->1079->1080->1230->1229->1228->2312->2313->2311->1228->1646->1645->1647->1228->1080->585->1392->1390->1391->1460->2089->2090->2091->1460->1619->1620->1618->1460->1459->1461->1391->1394->2672->2671->2673->1394->1393->1395->1391->585->583->46->48->47->621->619->620->843->842->841->1097->1098->1096->2967->2966->2965->1096->841->620->47->104->105->103->966->964->965->103->47->163->164->2844->2843->2842->164->1757->1756->1758->164->165->47->33->450->448->1994->1993->2676->2958->2956->2957->2676->2674->2675->1993->1995->448->449->33->139->1109->1110->1259->1260->2214->2212->2213->1260->1258->1110->1108->139->140->141->249->247->684->683->682->247->2500->2501->2502->247->248->2412->2410->2411->248->2486->2487->2485->248->1251->1249->1250->248->141->33->152->607->663->2472->2470->2759->2758->2760->2470->2471->663->662->661->2515->2516->2517->661->607->608->609->152->151->216->1546->1548->1547->216->215->214->566->565->567->214->327->564->1922->1923->2511->2510->2509->1923->1921->564->562->1051->1052->1053->2364->2960->2961->2959->2364->2362->2363->1053->562->1331->1332->1330->562->563->327->325->921->920->2817->2816->2815->920->919->325->326->900->2830->2832->2831->900->2968->2969->2970->900->899->898->326->716->773->774->772->828->826->827->772->716->717->715->326->214->151->153->161->266->860->2974->2975->2976->860->859->2659->2660->2661->859->861->266->1657->1658->1659->266->265->422->729->1049->1050->1048->2360->2361->2359->1048->729->728->727->422->2281->2283->2282->422->421->423->479->1654->1655->1656->479->480->1042->1043->1044->480->478->687->2318->2319->2317->687->686->929->928->930->686->691->692->1884->1882->2947->2949->2948->1882->2838->2836->2837->1882->1883->692->1512->1511->2047->2049->2518->2520->2818->2820->2819->2520->2519->2049->2048->1511->1510->2463->2462->2461->1510->692->693->686->685->478->423->265->267->818->817->1296->1294->1865->1864->1866->2422->2423->2424->1866->1294->1295->817->819->1138->1139->1282->1283->1284->1139->1140->819->267->161->1266->2139->2137->2138->1266->1265->1264->161->160->2321->2320->2322->160->162->153->33->1613->1614->1612->33->31->90->814->1538->1537->1539->814->815->1565->1566->1651->1653->1652->1566->1564->815->816->90->88->1024->1026->1025->88->123->431->2019->2066->2065->2067->2019->2017->2018->431->430->2780->2781->2951->2952->2950->2781->2779->430->432->123->381->379->472->952->954->1409->1408->1410->954->953->1162->1164->1163->953->472->1784->1785->1783->472->473->474->379->380->2243->2242->2244->380->123->121->251->894->893->2337->2335->2336->893->892->251->570->569->568->2825->2826->2824->568->251->252->250->922->923->1417->1419->1418->923->924->1860->1858->1859->924->250->121->1637->1638->2107->2195->2194->2196->2107->2109->2108->1638->1636->121->1369->1370->1371->121->1134->1701->1876->1877->1878->1701->1700->1699->1134->1353->1352->1351->1134->1133->1132->121->122->88->209->208->360->358->359->519->2264->2265->2263->519->517->518->359->208->210->88->89->1106->1105->1107->89->31->25->26->353->419->1298->1642->1643->1644->1298->1297->1299->419->2340->2339->2338->419->418->445->696->1753->1755->1754->696->694->1630->1631->1632->694->695->845->846->2070->2069->2068->846->844->695->445->1236->1234->1235->1611->1610->1609->1235->1380->1378->1622->1621->1623->1378->1379->1235->445->446->447->640->642->641->643->644->942->941->940->644->645->2810->2811->2809->645->641->1498->1499->1500->641->447->418->433->435->434->1316->1317->1315->434->418->420->353->363->2401->2402->2403->363->362->888->886->887->1447->1449->1448->887->362->361->1292->1291->2565->2563->2564->1291->1293->361->353->352->1853->1852->1854->352->354->26->39->1102->1103->2147->2148->2146->2397->2396->2395->2146->1103->1170->1168->1169->1239->1237->1238->1169->1103->1104->39->37->96->1686->1685->1684->96->201->199->200->1872->2657->2656->2658->1872->1871->1870->200->96->2416->2417->2418->96->677->676->678->96->94->133->858->2028->2026->2027->858->857->1032->2706->2704->2705->1032->1030->1252->2600->2599->2601->1252->1254->1253->1030->1031->857->1737->2448->2447->2446->1737->1735->1736->857->856->133->259->260->2865->2863->2864->260->261->133->135->134->2229->2227->2664->2662->2663->2227->2228->134->94->2248->2279->2280->2278->2248->2250->2249->94->95->37->1089->1088->1087->2980->2981->2982->1087->37->38->26->44->364->404->403->2072->2289->2287->2288->2072->2073->2071->403->405->364->366->365->513->511->2808->3000->2998->2999->2808->2807->2806->511->512->2308->2310->2309->512->365->44->43->227->228->226->1384->1385->1386->226->43->45->306->305->1911->1910->1909->305->2357->2358->2356->305->304->1006->1008->1007->304->1344->1343->1342->304->45->60->187->2183->2184->2182->187->189->335->2616->2615->2614->335->336->334->189->188->357->355->1085->2385->2384->2771->2770->2772->2893->2894->2895->2772->2384->2738->2737->2739->2384->2383->1085->1245->1243->2141->2142->2140->2697->2695->2696->2140->1243->1427->1428->1426->1243->1244->1085->1084->1086->355->1540->1541->1542->355->1801->1802->1803->355->356->188->60->2575->2577->2576->60->58->100->813->811->812->100->102->724->725->926->925->927->1255->1335->1334->1751->1752->2698->2700->2699->1752->1857->1855->1856->1752->1750->1334->1333->1255->1256->1452->1450->1451->1256->1257->927->725->726->1988->1989->1987->726->102->219->788->1798->1800->1799->788->789->787->1851->2559->2557->2906->2907->2905->2557->2558->2993->2994->2992->2558->1851->1849->1850->787->219->218->217->501->1072->1074->2562->2561->2560->1074->1073->501->500->1113->1111->1112->500->1190->1189->1518->1517->1516->1189->1191->500->1689->1687->1688->500->1945->1947->2291->2292->2290->1947->1946->500->499->1936->1938->1937->499->217->102->101->329->411->1481->1482->1480->2092->2093->2724->2723->2722->2093->2094->1480->411->410->1962->1960->1961->410->2649->2648->2647->410->409->823->1489->1491->1490->1588->1590->2326->2327->2328->1590->1589->2381->2380->2382->1589->1490->823->824->2373->2372->2371->824->825->409->329->330->328->101->339->338->337->101->370->713->1423->1424->1425->713->712->714->370->371->372->1698->1697->1696->372->101->58->59->62->63->61->59->45->2350->2441->2440->2442->2350->2352->2351->2714->2715->2713->2351->45->26->5->4->69->67->68->672->671->2586->2585->2584->671->670->829->1141->1142->1382->1383->1381->1142->1143->829->831->830->670->753->751->1220->1221->1219->751->752->848->847->849->752->670->68->2595->2593->2594->68->4->1271->1272->1270->1312->2302->2304->2303->1312->1314->1313->1270->4->157->1404->1403->1810->1811->1812->1403->1402->157->159->158->529->530->1200->1199->1896->1894->2053->2054->2055->1894->1895->1199->1795->1796->1797->1199->1198->530->531->158->4->182->181->415->417->454->455->2749->2751->2750->455->1205->1570->1572->1571->1205->1206->1204->455->2755->2756->2757->455->456->1045->2763->2762->2761->1045->1046->2719->2721->2720->1046->1047->2887->2888->2889->1047->456->417->416->181->183->1694->1695->2768->2767->2769->1695->1693->183->207->205->206->557->558->556->206->1557->2011->2013->2012->1557->1556->2155->2157->2156->1556->1555->206->183->4->6->871->873->2785->2786->2787->873->872->6->2->0->870->1704->1702->1703->870->869->868->0->1951->1952->2498->2497->2829->2827->2828->2497->2499->1952->1953->0->3->1->71->1059->1057->1058->71->233->232->1280->1279->1281->232->234->1011->1010->1227->1226->1225->1010->1009->234->1824->1822->1823->2617->2619->2618->1823->234->71->70->136->721->1182->1181->1180->721->722->1311->1309->1806->1805->1804->1309->1310->722->723->2983->2985->2984->723->1581->1580->1733->2506->2507->2508->1733->1732->1734->1580->1579->1729->2127->2125->2620->2622->2621->2125->2126->1729->1730->1731->1579->723->136->572->690->689->688->572->573->571->136->138->810->1722->1720->1721->810->809->1934->1935->1933->809->808->2634->2632->2633->808->138->623->622->1288->1290->1289->1339->1340->1341->1289->622->624->138->503->504->1915->1916->1917->504->502->138->2404->2406->2405->138->2096->2095->2097->138->137->70->72->168->167->166->275->998->1530->1529->1528->1615->1616->1617->1793->2258->2259->2257->1793->1794->1792->2989->2990->2991->1792->1617->1528->998->997->999->275->274->393->534->2571->2569->2570->534->532->533->393->1964->1965->1963->393->392->2784->2783->2782->392->391->274->310->311->2175->2174->2173->311->784->785->786->1648->1649->1650->2430->2429->2428->1650->786->311->312->274->2875->2876->2877->274->276->1176->1567->1569->1568->1176->1175->1174->276->166->72->318->316->1748->1749->1747->316->317->521->520->522->1908->1906->1907->522->1094->1095->1412->1411->1413->1095->1093->522->317->72->1->2->2160->2158->2159->2->40->41->436->438->2626->2627->2628->2776->2778->2777->2628->438->437->528->1714->1715->1716->528->527->526->437->41->2866->2867->2868->41->42->1082->1083->1081->42->129->230->710->1772->1771->1773->710->709->1762->1764->2467->2469->2468->1764->1763->709->711->230->1440->1438->1439->230->2255->2256->2254->230->231->1321->1323->1322->231->229->1014->2604->2603->2602->2644->2645->2646->2602->1014->1012->1013->229->129->127->128->170->171->399->397->1173->1172->1171->397->398->1183->1184->1185->398->2129->2573->2574->2572->2129->2128->2130->398->171->1328->2679->2678->2677->1328->1327->1329->171->169->492->490->491->169->128->42->1766->1767->1765->42->2->5->634->775->777->776->2045->2046->2044->776->2205->2203->2204->776->2481->2480->2479->776->634->635->2504->2505->2503->635->636->706->707->746->762->2400->2399->2398->762->761->760->1526->1527->1525->1778->1779->1777->1525->760->746->745->1218->2247->2245->2246->1218->1717->1718->1719->1218->1501->2544->2542->2543->1501->1502->1503->1218->1217->2606->2607->2605->1217->1216->745->747->707->708->636->5->9->580->582->581->763->765->1544->1543->1545->765->764->2902->2904->2971->2973->2972->2904->2903->764->581->9->7->630->889->891->890->630->628->2390->2389->2391->628->629->895->897->896->629->7->8->11->289->290->291->11->12->992->993->2475->2474->2473->993->991->12->99->1667->1666->1668->99->341->412->414->425->424->426->1551->1549->1550->426->486->485->2329->2996->2995->2997->2329->2549->2550->2548->2329->2331->2330->485->2394->2393->2392->485->484->2636->2637->2635->484->426->414->413->1942->1943->1944->2681->2680->2682->1944->413->341->340->885->883->884->340->590->972->971->1920->1919->1918->971->970->590->591->1186->1187->1188->591->589->754->756->755->589->1886->2103->2102->2101->1886->1887->2179->2181->2180->1887->1978->1980->1979->1887->1885->589->340->342->99->98->2316->2314->2476->2477->2478->2314->2315->98->97->386->730->732->731->2840->2839->2939->2940->2938->2839->2841->731->386->387->1492->1673->1674->1738->1739->1787->1786->1788->2623->2625->2624->1788->2293->2294->2295->1788->1739->1740->1957->1958->2057->2056->2058->1958->1959->2122->2123->2124->1959->1740->1674->1672->1492->1493->1494->1843->1844->1845->1494->387->385->97->12->10->73->75->74->460->487->489->488->460->462->514->515->675->674->673->2238->2237->2236->2369->2368->2581->2582->2583->2368->2370->2236->673->515->516->462->461->74->958->1377->1375->1376->958->959->960->2650->2652->2651->960->1268->1267->1269->960->74->10->51->253->933->931->932->1120->1122->1121->1357->1359->1358->1121->932->253->272->1000->1119->1117->1118->1000->1001->1002->272->273->1914->1913->1912->273->2166->2165->2164->273->271->2534->2533->2535->271->1144->1145->1146->271->253->254->2208->2207->2206->254->255->743->1348->1350->1349->743->2039->2040->2038->743->742->1531->2927->2926->2928->1531->1532->1533->742->744->255->51->300->1038->1037->1036->300->2117->2116->2118->300->298->299->51->49->50->1004->1005->1003->50->1231->1232->1233->50->1468->1470->1469->50->10->16->192->190->1901->1902->1900->190->191->1416->1415->2083->2333->2332->2334->2083->2084->2085->1415->1414->191->16->19->54->113->277->279->1326->1325->2953->2955->2954->1325->1324->279->278->1825->1826->1827->2494->2496->2495->1827->278->113->112->256->986->985->987->256->258->257->1926->1925->1924->257->112->173->172->174->112->114->1153->2460->2631->2630->2629->2460->2458->2459->1153->1606->1607->1608->1153->1155->1154->114->145->146->701->700->702->146->1262->1263->1261->146->586->1495->1497->1496->1982->1983->2796->2794->2795->1983->1981->1496->2087->2086->2088->1496->586->588->587->981->980->1015->1017->1016->980->979->587->719->1373->1374->2555->2554->2556->1374->1372->719->1956->2943->2941->2942->1956->1955->1954->719->718->822->820->821->718->720->587->1128->1126->1127->587->146->147->882->1582->1903->1904->1905->1582->1584->1583->2527->2528->2529->1583->882->881->880->147->114->2640->2639->2638->114->303->598->600->599->303->2271->2270->2269->303->301->302->2036->2035->2037->302->114->54->2610->2609->2608->54->53->125->389->388->390->125->124->1421->1422->1420->124->126->877->878->1405->1406->1407->878->879->126->53->1835->1834->1836->53->52->19->21->20->262->264->263->20->16->17->132->496->498->497->132->131->130->384->382->383->442->804->803->862->864->863->803->802->1158->1157->1156->802->442->443->444->2666->2667->2665->444->383->130->1998->1996->1997->130->17->18->2835->2833->2834->18->36->117->115->1027->1028->1456->1458->1457->1028->1029->115->116->36->119->143->2376->2375->2374->143->142->406->2728->2729->2730->406->407->408->2484->2482->2483->2855->2856->2854->2483->408->142->1484->1483->1485->1869->1867->1868->1485->142->144->1367->1366->1368->144->154->2296->2298->2297->154->155->505->506->1927->1929->1928->506->507->155->193->2929->2931->2930->193->2702->2701->2703->193->194->1396->1398->1397->194->195->2814->2812->2813->195->155->156->441->781->2491->2492->2493->781->782->783->441->440->771->852->851->978->977->2919->2917->2918->977->976->1033->1240->1241->1242->1033->1035->1034->976->851->850->771->769->770->440->439->1814->2736->2735->2734->1814->1813->1815->439->2445->2444->2443->439->1092->1090->2342->2341->2343->1090->1091->1356->2689->2691->2690->1356->1355->1354->1091->1362->1360->1361->1091->439->156->144->119->118->120->483->481->482->2823->2821->2822->2860->2862->2861->2822->482->749->750->748->482->1363->2379->2377->2378->1363->1364->1365->482->120->36->35->34->244->368->805->806->2852->2853->2851->806->807->368->367->523->963->961->962->523->2225->2226->2224->523->524->654->652->1213->1214->1215->1670->2221->2223->2222->1670->1669->1671->1215->652->653->524->1166->1165->1167->524->525->2185->2186->2187->525->367->1136->1135->1137->2513->2514->2512->1137->367->369->244->245->308->307->314->1967->1966->1968->314->313->315->2105->2104->2106->315->307->309->245->246->34->1287->1285->1890->1889->2741->2740->2742->1889->1888->1285->1286->34->18->457->458->561->578->579->577->778->779->1863->1861->1862->779->853->1846->1848->1847->853->1743->1741->1742->853->854->1873->1875->1874->854->855->779->780->1018->1020->1019->780->577->561->1076->1077->1075->1151->1152->1150->1075->561->559->2597->2596->2598->559->560->458->459->1304->1303->2136->2754->2752->2753->2136->2135->2421->2420->2745->2744->2743->2420->2419->2135->2134->1303->1305->459->18->550->551->2016->2015->2803->2805->2804->2015->2014->551->552->1115->1114\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def get_all_path(filename):\n",
    "    with open(filename) as fp:\n",
    "        lines = fp.readlines()\n",
    "\n",
    "    all_paths = []\n",
    "    split_nodes = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.split(' -> ')\n",
    "        line = [i.strip() for i in line]\n",
    "        if ',' in line[1]:\n",
    "            line[0] = int(line[0])\n",
    "            split_nodes.append(line[0])\n",
    "            line[1] = list(map(int, line[1].split(','))) \n",
    "            new_list = [[line[0], i] for i in line[1]]\n",
    "            all_paths += new_list\n",
    "            \n",
    "        else:\n",
    "            line = list(map(int, line))\n",
    "            all_paths.append(line)\n",
    "\n",
    "    return all_paths\n",
    "\n",
    "def get_one_cycle(origin_paths, all_paths):\n",
    "    all_paths_copy = all_paths[:]\n",
    "    for remain_path in origin_paths:\n",
    "        if remain_path in all_paths_copy:\n",
    "            all_paths_copy.remove(remain_path)\n",
    "    if origin_paths==[]:\n",
    "        start = random.choice(all_paths)\n",
    "    else:\n",
    "        start = origin_paths[-1][1]\n",
    "    \n",
    "    while True:\n",
    "        for path in all_paths_copy:\n",
    "            if path[0] == start:\n",
    "                origin_paths.append(path)\n",
    "                all_paths_copy.remove(path)\n",
    "                start = path[1]\n",
    "        if origin_paths[-1][1] == origin_paths[0][0]:\n",
    "            break\n",
    "    \n",
    "    return origin_paths, all_paths_copy\n",
    "        \n",
    "\n",
    "def iter_cycle(all_paths):\n",
    "    \n",
    "    start_path =[random.choice(all_paths)]\n",
    "    all_paths_copy = all_paths[:]\n",
    "\n",
    "    Cycle, remain_all_paths = get_one_cycle(start_path, all_paths=all_paths_copy)\n",
    "    \n",
    "    while len(remain_all_paths) != 0:\n",
    "        \n",
    "        subcycle = None\n",
    "        for i in range(len(Cycle)):\n",
    "            for remain_path in remain_all_paths:\n",
    "                if Cycle[i][1]==remain_path[0]:\n",
    "                    start_edge = remain_path\n",
    "                    subcycle, remain_all_paths = get_one_cycle([start_edge], remain_all_paths)\n",
    "                    break\n",
    "            if subcycle != None:\n",
    "                break\n",
    "        \n",
    "        Cycle = Cycle[:i+1] + subcycle + Cycle[i+1:]\n",
    "        \n",
    "    return Cycle\n",
    "              \n",
    "\n",
    "all_paths = get_all_path('rosalind_ba3f.txt')\n",
    "cycle_result = iter_cycle(all_paths)\n",
    "\n",
    "path_result = []\n",
    "for i in range(len(cycle_result)):\n",
    "    if i == 0:\n",
    "        path_result += cycle_result[i]\n",
    "    else:\n",
    "        path_result += [cycle_result[i][1]]\n",
    "\n",
    "print('->'.join(list(map(str, path_result)))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3G 欧拉路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_path(filename):\n",
    "    with open(filename) as fp:\n",
    "        lines = fp.readlines()\n",
    "\n",
    "    all_paths = []\n",
    "    split_nodes = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.split(' -> ')\n",
    "        line = [i.strip() for i in line]\n",
    "        if ',' in line[1]:\n",
    "            line[0] = int(line[0])\n",
    "            split_nodes.append(line[0])\n",
    "            line[1] = list(map(int, line[1].split(','))) \n",
    "            new_list = [[line[0], i] for i in line[1]]\n",
    "            all_paths += new_list\n",
    "            \n",
    "        else:\n",
    "            line = list(map(int, line))\n",
    "            all_paths.append(line)\n",
    "\n",
    "    return all_paths\n",
    "\n",
    "\n",
    "\n",
    "def select_start_and_end(all_paths):\n",
    "    out_count = [all_path[0] for all_path in all_paths]\n",
    "    in_count = [all_path[1] for all_path in all_paths]\n",
    "    \n",
    "    result_dict = {}\n",
    "    for node in set(in_count + out_count):\n",
    "        result_dict[node] = (in_count.count(node), out_count.count(node))\n",
    "\n",
    "    for node in result_dict.keys():\n",
    "        if result_dict[node][1] - result_dict[node][0] == 1:\n",
    "            start_node = node\n",
    "        elif result_dict[node][0] - result_dict[node][1] == 1:\n",
    "            end_node = node\n",
    "            \n",
    "    return start_node, end_node\n",
    "\n",
    "        \n",
    "# all_paths = get_all_path('rosalind_ba3g.txt')\n",
    "# start_node, end_node = select_start_and_end(all_paths)\n",
    "# all_paths.append(['*', start_node])\n",
    "# all_paths.append([end_node, '*'])\n",
    "\n",
    "\n",
    "# cycle_result = iter_cycle(all_paths)\n",
    "\n",
    "# path_result = []\n",
    "# for i in range(len(cycle_result)):\n",
    "#     if i == 0:\n",
    "#         path_result += cycle_result[i]\n",
    "#     else:\n",
    "#         path_result += [cycle_result[i][1]]\n",
    "\n",
    "# index = path_result.index('*')\n",
    "\n",
    "# path_result = path_result[index+1:-1] + path_result[:index]\n",
    "\n",
    "# print('->'.join(list(map(str, path_result))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(kmer_list):\n",
    "    result = ''.join([kmer_list[i] if i == 0 else kmer_list[i][-1] for i in range(len(kmer_list))])\n",
    "    return result\n",
    "\n",
    "def De_Bruijn_Graph(kmer_list):\n",
    "    result_dict = {}\n",
    "    for kmer in kmer_list:\n",
    "        pair1 = kmer[:-1]\n",
    "        pair2 = kmer[1:]\n",
    "        if pair1 in result_dict.keys():\n",
    "            result_dict[pair1].append(pair2)\n",
    "        else:\n",
    "            result_dict[pair1] = [pair2]\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "def get_all_path(filename):\n",
    "    with open(filename) as fp:\n",
    "        lines = fp.readlines()\n",
    "\n",
    "    all_paths = []\n",
    "    split_nodes = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.split(' -> ')\n",
    "        line = [i.strip() for i in line]\n",
    "        if ',' in line[1]:\n",
    "            line[0] = int(line[0])\n",
    "            split_nodes.append(line[0])\n",
    "            line[1] = list(map(int, line[1].split(','))) \n",
    "            new_list = [[line[0], i] for i in line[1]]\n",
    "            all_paths += new_list\n",
    "            \n",
    "        else:\n",
    "            line = list(map(int, line))\n",
    "            all_paths.append(line)\n",
    "\n",
    "    return all_paths\n",
    "\n",
    "\n",
    "\n",
    "def select_start_and_end(all_paths):\n",
    "    out_count = [all_path[0] for all_path in all_paths]\n",
    "    in_count = [all_path[1] for all_path in all_paths]\n",
    "    \n",
    "    result_dict = {}\n",
    "    for node in set(in_count + out_count):\n",
    "        result_dict[node] = (in_count.count(node), out_count.count(node))\n",
    "\n",
    "    for node in result_dict.keys():\n",
    "        if result_dict[node][1] - result_dict[node][0] == 1:\n",
    "            start_node = node\n",
    "        elif result_dict[node][0] - result_dict[node][1] == 1:\n",
    "            end_node = node\n",
    "            \n",
    "    return start_node, end_node\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_seq_from_kmers(kmers):\n",
    "    \n",
    "    result_dict = De_Bruijn_Graph(kmers)\n",
    "\n",
    "    all_paths = []\n",
    "    for key, value in result_dict.items():\n",
    "        if len(value) > 1:\n",
    "            for iter in value:\n",
    "                all_paths.append([key, iter])\n",
    "        else:\n",
    "            all_paths.append([key, value[0]])\n",
    "\n",
    "    start_node, end_node = select_start_and_end(all_paths)\n",
    "    all_paths.append(['*', start_node])\n",
    "    all_paths.append([end_node, '*'])\n",
    "\n",
    "\n",
    "    cycle_result = iter_cycle(all_paths)\n",
    "\n",
    "    path_result = []\n",
    "    for i in range(len(cycle_result)):\n",
    "        if i == 0:\n",
    "            path_result += cycle_result[i]\n",
    "        else:\n",
    "            path_result += [cycle_result[i][1]]\n",
    "\n",
    "    index = path_result.index('*')\n",
    "\n",
    "    path_result = path_result[index+1:-1] + path_result[:index]\n",
    "    \n",
    "    return get_seq(path_result)\n",
    "   \n",
    "# with open('rosalind_ba3h.txt') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     k = int(lines[0].strip())\n",
    "#     kmers = lines[1:]\n",
    "#     kmers = [line.strip() for line in kmers]\n",
    "    \n",
    "\n",
    "# print(get_seq_from_kmers(kmers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3I 长度为k的二进制字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_k_string(k):\n",
    "    if k== 1:\n",
    "        return [['0'],['1']]\n",
    "    else:\n",
    "        return [string + ['0'] for string in get_all_k_string(k-1)] + [string + ['1'] for string in get_all_k_string(k-1)]\n",
    "\n",
    "def De_Bruijn_Graph(kmer_list):\n",
    "    result_dict = {}\n",
    "    for kmer in kmer_list:\n",
    "        pair1 = kmer[:-1]\n",
    "        pair2 = kmer[1:]\n",
    "        if pair1 in result_dict.keys():\n",
    "            result_dict[pair1].append(pair2)\n",
    "        else:\n",
    "            result_dict[pair1] = [pair2]\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# with open('rosalind_ba3i.txt') as fp:\n",
    "#     k = int(fp.readline().strip())\n",
    "        \n",
    "# string_list = [''.join(string) for string in get_all_k_string(k)]\n",
    "        \n",
    "# result_dict = De_Bruijn_Graph(string_list)\n",
    "\n",
    "# all_paths = []\n",
    "# for key, value in result_dict.items():\n",
    "#     if len(value) > 1:\n",
    "#         for iter in value:\n",
    "#             all_paths.append([key, iter])\n",
    "#     else:\n",
    "#         all_paths.append([key, value[0]])\n",
    "\n",
    "# cycle_result = iter_cycle(all_paths)\n",
    "\n",
    "# path_result = []\n",
    "# for i in range(len(cycle_result)):\n",
    "#     if i == 0:\n",
    "#         path_result += cycle_result[i]\n",
    "#     else:\n",
    "#         path_result += [cycle_result[i][1]]      \n",
    "\n",
    "# seq = get_seq(path_result)\n",
    "\n",
    "# print(seq[:(len(seq)-len(path_result[0]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAACCATTTTGTGGGCTGCGGTGTCACATATTTGTCCGCAGCAGAGTTCTCAATTTGTCGTGGTCCGAGAAACCATATGTTATGATAATGTCATACACCATGCACTGGTAGGGGTCCGAGAAACCATATGTTATGATAATGTCGCTACAAAGACCAATACCTTCACAGACGGTCCGAGAAACCATATGTTATGATAATGTCTACTGTAGTAGCCGGGTTCGCCCAGCAATGCATGAGCGGATAGAACCGATTGCGTAGTCCGAGAGTCCGAGAAACCATATGTTATGATAATGTCAACCATATGTTATGATAATGTCCTGACCGATACGAGACTGCAACGTAGAACGGTTTTTACGAACAAACCGCGGTCCGAGAAACCATATGTTATGATAATGTCTTCAACCCTGGGCTTCTCATAGTCCCTCCACCAATAACGAGTCCGAGAAACCATATGTTATGATAATGTCTAAAGACGATGTCAAATGGACCTAAACATTTAAATGTGCTTATATCAGGGTCCCTGAGCAGATAAAGCCGATAAAGCTCCCCAAGGGAATGTCAGTGCTTTACTCAGCCTGACCCGCAAGGTTCGGTCAGTTGGGACAACGTCTTGCGCTAACCCGACGTTGAGTCCGAGAAACCATATGTTATGATAATGTCCCTCTGAGTTCACCGAGTCAGGAGGGCAAATAGCTCTGGGGTACTCGGTTTGGAATAGCATGCCCCTCGCTTAGTGAGCACCCGTTTCGTGTCTTGGACCGAGATTGGCCGAACATGTAGGAATCCATGTGATTGACTCCGTCCGAGAAACCATATGTTATGATAATGTCGGCTACGCATTGTTCCCTCTTATGTATGATGTCCCTCCCGATCCGGATGTGTAGCCACCCACAAAGGTGTCCGGTCCGAGAAACCATATGTTATGATAATGTCAGAAACCATATGTTATGATAATGTCCCGAGAAACCATATGTTATGATAATGTCTAGTGCTCACCGTCACCTATCATTTACAAAACTCAGCGCTCATGTGAGGTGTCGCTCAAAAGACTCACAAAGGTAGGGATACGCTTATATTCGCGGGTCATGTGGGGGTCTAGACAGGGTCCGAGAAACCATATGTTATGATAATGTCTTATCCGCCACTCATGTAATACACGTTGGGTAAGGTTCCCTCTCCGAGTCGCTTTCGTCCGAGAAACCATATGTTATGATAATGTCGAATAAGTCCGAGAAACCATATGTTATGATAATGTCCAGGGCGGTGTTGCCTTTGTGGAGAAATTGACTGTGTATTTTATTATGATTGTTGGGTTAAGGGCTGCAACTGCCTTTTCTCGCGCGGACACCCCCGGTCTCATATGGCGCCAATGCGTCTGTCCACCTTGGTGCCGCTGAGCCAATTGATACAGTCTGATCAGGTCAAATGGCTTGAGGCGGTGCGCGGCCCG\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "def build_paired_de_bruijn_graph(paired_reads, k, d):\n",
    "    graph = defaultdict(list)\n",
    "    for pair in paired_reads:\n",
    "        prefix = (pair[0][:-1], pair[1][:-1])\n",
    "        suffix = (pair[0][1:], pair[1][1:])\n",
    "        graph[prefix].append(suffix)\n",
    "    return graph\n",
    "\n",
    "def find_eulerian_path(graph):\n",
    "    \n",
    "    out_degree = defaultdict(int)\n",
    "    in_degree = defaultdict(int)\n",
    "    for node, neighbors in graph.items():\n",
    "        out_degree[node] += len(neighbors)\n",
    "        for neighbor in neighbors:\n",
    "            in_degree[neighbor] += 1\n",
    "\n",
    "    start_node, end_node = None, None\n",
    "    for node in set(out_degree) | set(in_degree):\n",
    "        out_count = out_degree[node]\n",
    "        in_count = in_degree[node]\n",
    "        if out_count > in_count:\n",
    "            start_node = node\n",
    "        elif in_count > out_count:\n",
    "            end_node = node\n",
    "    \n",
    "    # 若找到了不平衡的节点，添加额外边以平衡图\n",
    "    if start_node and end_node:\n",
    "        graph[end_node].append(start_node)\n",
    "\n",
    "    # Hierholzer算法求欧拉路径\n",
    "    def visit(node):\n",
    "        stack = [node]\n",
    "        path = []\n",
    "        while stack:\n",
    "            if graph[stack[-1]]:\n",
    "                next_node = graph[stack[-1]].pop()\n",
    "                stack.append(next_node)\n",
    "            else:\n",
    "                path.append(stack.pop())\n",
    "        return path[::-1]\n",
    "\n",
    "    # 找到欧拉路径并去掉额外边\n",
    "    path = visit(start_node if start_node else list(graph.keys())[0])\n",
    "    return path[:-1] if start_node and end_node else path\n",
    "\n",
    "def reconstruct_string_from_path(path, k, d):\n",
    "    prefix_string = path[0][0]\n",
    "    suffix_string = path[0][1]\n",
    "\n",
    "    for prefix, suffix in path[1:]:\n",
    "        prefix_string += prefix[-1]\n",
    "        suffix_string += suffix[-1]\n",
    "\n",
    "    return prefix_string + suffix_string[-(k + d):]\n",
    "\n",
    "def string_reconstruction_from_paired_composition(k, d, paired_reads):\n",
    "    graph = build_paired_de_bruijn_graph(paired_reads, k, d)\n",
    "    eulerian_path = find_eulerian_path(graph)\n",
    "    return reconstruct_string_from_path(eulerian_path, k, d)\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename) as fp:\n",
    "        lines = fp.readlines()\n",
    "        k, d  = tuple(lines[0].strip().split(' '))\n",
    "        pairs = [tuple(line.strip().split('|')) for line in lines[1:]]\n",
    "        \n",
    "    return int(k), int(d), pairs\n",
    "\n",
    "k, d, pairs = read_file('rosalind_ba3j.txt')\n",
    "print(string_reconstruction_from_paired_composition(k, d, pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def split(kmers):\n",
    "    return [(kmer[:-1], kmer[1:]) for kmer in kmers]\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename) as fp:\n",
    "        lines = fp.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "def make_graph(pair_nodes):\n",
    "    graph = defaultdict(list)\n",
    "    in_count = defaultdict(int)\n",
    "    out_count = defaultdict(int)\n",
    "    for pair_node in pair_nodes:\n",
    "        graph[pair_node[0]].append(pair_node[1])\n",
    "    \n",
    "    for node, neighbors in graph.items():\n",
    "        out_count[node] = len(neighbors)\n",
    "        for neigbor in neighbors:\n",
    "            in_count[neigbor] += 1\n",
    "            \n",
    "    return graph, in_count, out_count\n",
    "\n",
    "def find_balance_and_imbalance(graph, in_count, out_count):\n",
    "    balance_nodes = []\n",
    "    imbalance_nodes = []\n",
    "    for node in set(list(in_count.keys()) + list(out_count.keys())):\n",
    "        if in_count[node]==1 and out_count[node]==1:\n",
    "            balance_nodes.append(node)\n",
    "        else:\n",
    "            imbalance_nodes.append(node)\n",
    "    \n",
    "    return balance_nodes, imbalance_nodes\n",
    "\n",
    "def iter_path(paths ,all_result, balance_nodes, end_nodes, graph):\n",
    "    for path in paths:\n",
    "        for value in graph[path[-1]]:\n",
    "            if value in balance_nodes:\n",
    "                paths.append(path + [value])\n",
    "            elif value in end_nodes:\n",
    "                all_result.append(path + [value])\n",
    "        paths.remove(path)\n",
    "    return paths, all_result\n",
    "    \n",
    "def iter(start_nodes, balance_nodes, end_nodes, graph):\n",
    "    paths = [[start_node] for start_node in start_nodes]\n",
    "    all_result = []\n",
    "    while len(paths) != 0:\n",
    "        paths, all_result = iter_path(paths, all_result, balance_nodes, end_nodes, graph)\n",
    "    \n",
    "    return all_result\n",
    "            \n",
    "       \n",
    "def find_start_and_end(in_count, out_count, imbalance_nodes):\n",
    "    start_nodes = []\n",
    "    end_nodes = []\n",
    "    for imbalance_node in imbalance_nodes:\n",
    "        if out_count[imbalance_node] != 0:\n",
    "            start_nodes.append(imbalance_node)\n",
    "            \n",
    "        if in_count[imbalance_node] != 0:\n",
    "            end_nodes.append(imbalance_node)\n",
    "    \n",
    "    return start_nodes, end_nodes\n",
    "\n",
    "def get_config(results):\n",
    "    results_seq =  []\n",
    "    for result in results:\n",
    "        results_seq.append(''.join([result[i][:] if i==0 else result[i][-1] for i in range(len(result))]))\n",
    "    return results_seq\n",
    "    \n",
    "\n",
    "kmer_list = read_file('rosalind_ba3k.txt')\n",
    "graph , in_count, out_count = make_graph(split(kmer_list))\n",
    "balance_nodes, imbalance_nodes = find_balance_and_imbalance(graph, in_count, out_count)\n",
    "start_nodes, end_nodes = find_start_and_end(in_count, out_count, imbalance_nodes)\n",
    "results = iter(start_nodes, balance_nodes, end_nodes, graph)\n",
    "\n",
    "for i in get_config(results):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTTAGCCAACACTTGCGGGCCGATGTGTTTCTAATCATTAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACATTGGCGGAGCGGGAGTTTCACTAGTTTCACCCCTCTTGCAAGAGGCCCGTGATTAGAGCGTGACACGCGCAATCCCCCACCTTTAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACCACCTCTGATAATCATACAAGGGTAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACCAGTTCCGGAGGGTGAGGGAATAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACAATTACTCCTGCTACCCGTCTTCGGTTGGTTGGGAAGTTTTTTAGTGTTATAAAGGTCGGGCTAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCTAATCATACTAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACAATAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACGGGGCTGACTAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACAGCGTCGGGACTACAATCGTACGCCAACTTACCCGAAACTCAAGGCACGCAATGTTATTAAAGATATTTTTAGGCGCAGCGCACTAAACGCATCAAAAGAACCTGAACAACAATGTTAATTAATCTAATCATACAAGGGGCTGACTGCCTAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACAGGTGCTTGCCACCCAGCGTCGGGACATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGTAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACCGTCGGGACGCTCTGACAACGCGAGAGTGGGCGGAAGGTCTTATAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACAGGGAAACTCAGGACTTAGTACGCAGCTTTCAATAAGAGAAAAGTAGCCTATGAGTCTAGGATATAAATTCTAGACGCGAACTTTGCAGGGTCTATCGTCTGCACTAAGTTATCCATATATCTGTGGAAGTATAACGCTAATCATACAAGGGGTAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACGCTATACAATCGGGGTGCGGGTTCAGCTATCCTCCGTATTAGTCTAGCGTCGGGTGCAGTTGGTCAATACGGCCGCCCGGAACCTTTACTCTCTGGGATGTGCATATTCTATTACGTACTCTAGTTATTTCTAGCCGATGAATGGTAGATCTTTGGGCGGTGCGAATTTCTCGTGTACCAGGTTCACAGTTAAGAGTGGCGTTAGAAATGGCGGTGTGGCCAGTATTACAGAGAAATTAACTCCCTCGCCGATTGTCCGTCAGTTTAAGAATTACCCTGACACGTGCATGAAGGCATAGTCCGTCTTGGTCAGCGTAATCATACAAGGGGCTGACTGCCAGGTGCTTGCCACCCAGCGTCGGGACATTAAAGTTGAAACCTTTGGTTGCACCCCATAAACCACGGGTATATACGTTCGGCGTGCCAGATCGCCAGAAATTGCCCTGGAAGACCCTACAATATAGAAGCCTTGGAATAGCCAAATAGCACCACGAAATTTACTCGGTTACATTAGAGTACTTCGTGCCAAGCTTTTATAGTTGTTGACTGACAGATAATAGATGGC\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "def build_paired_de_bruijn_graph(paired_reads, k, d):\n",
    "    graph = defaultdict(list)\n",
    "    for pair in paired_reads:\n",
    "        prefix = (pair[0][:-1], pair[1][:-1])\n",
    "        suffix = (pair[0][1:], pair[1][1:])\n",
    "        graph[prefix].append(suffix)\n",
    "    return graph\n",
    "\n",
    "def find_eulerian_path(graph):\n",
    "    \n",
    "    out_degree = defaultdict(int)\n",
    "    in_degree = defaultdict(int)\n",
    "    for node, neighbors in graph.items():\n",
    "        out_degree[node] += len(neighbors)\n",
    "        for neighbor in neighbors:\n",
    "            in_degree[neighbor] += 1\n",
    "\n",
    "    start_node, end_node = None, None\n",
    "    for node in set(out_degree) | set(in_degree):\n",
    "        out_count = out_degree[node]\n",
    "        in_count = in_degree[node]\n",
    "        if out_count > in_count:\n",
    "            start_node = node\n",
    "        elif in_count > out_count:\n",
    "            end_node = node\n",
    "    \n",
    "    # 若找到了不平衡的节点，添加额外边以平衡图\n",
    "    if start_node and end_node:\n",
    "        graph[end_node].append(start_node)\n",
    "\n",
    "    # Hierholzer算法求欧拉路径\n",
    "    def visit(node):\n",
    "        stack = [node]\n",
    "        path = []\n",
    "        while stack:\n",
    "            if graph[stack[-1]]:\n",
    "                next_node = graph[stack[-1]].pop()\n",
    "                stack.append(next_node)\n",
    "            else:\n",
    "                path.append(stack.pop())\n",
    "        return path[::-1]\n",
    "\n",
    "    # 找到欧拉路径并去掉额外边\n",
    "    path = visit(start_node if start_node else list(graph.keys())[0])\n",
    "    return path[:-1] if start_node and end_node else path\n",
    "\n",
    "def reconstruct_string_from_path(path, k, d):\n",
    "    prefix_string = path[0][0]\n",
    "    suffix_string = path[0][1]\n",
    "\n",
    "    for prefix, suffix in path[1:]:\n",
    "        prefix_string += prefix[-1]\n",
    "        suffix_string += suffix[-1]\n",
    "\n",
    "    return prefix_string + suffix_string[-(k + d):]\n",
    "\n",
    "def string_reconstruction_from_paired_composition(k, d, paired_reads):\n",
    "    graph = build_paired_de_bruijn_graph(paired_reads, k, d)\n",
    "    eulerian_path = find_eulerian_path(graph)\n",
    "    return reconstruct_string_from_path(eulerian_path, k, d)\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename) as fp:\n",
    "        lines = fp.readlines()\n",
    "        k, d  = tuple(lines[0].strip().split(' '))\n",
    "        pairs = [tuple(line.strip().split('|')) for line in lines[1:]]\n",
    "        \n",
    "    return int(k), int(d), pairs\n",
    "\n",
    "k, d, pairs = read_file('rosalind_ba3l.txt')\n",
    "print(string_reconstruction_from_paired_composition(k, d, pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BA3M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 -> 280\n",
      "312 -> 216\n",
      "388 -> 2\n",
      "248 -> 378\n",
      "189 -> 316\n",
      "103 -> 323\n",
      "305 -> 278\n",
      "156 -> 308\n",
      "232 -> 265\n",
      "327 -> 271\n",
      "283 -> 369\n",
      "226 -> 4\n",
      "312 -> 0 -> 119 -> 134 -> 216\n",
      "103 -> 27 -> 166 -> 326 -> 237 -> 323\n",
      "59 -> 181\n",
      "102 -> 335\n",
      "316 -> 227 -> 105 -> 332 -> 244 -> 49 -> 68 -> 327\n",
      "123 -> 160 -> 338 -> 198 -> 33 -> 13 -> 280\n",
      "59 -> 294 -> 181\n",
      "189 -> 18 -> 110 -> 201 -> 150 -> 356 -> 21 -> 394 -> 159 -> 242 -> 316\n",
      "378 -> 67 -> 70 -> 28 -> 186 -> 305\n",
      "280 -> 360 -> 352 -> 344 -> 309 -> 197 -> 358 -> 298 -> 96 -> 163 -> 189\n",
      "226 -> 98 -> 132 -> 254 -> 19 -> 315 -> 155 -> 249 -> 4\n",
      "283 -> 383 -> 395 -> 195 -> 386 -> 170 -> 133 -> 151 -> 153 -> 369\n",
      "335 -> 212 -> 1 -> 93 -> 121 -> 313 -> 127 -> 248\n",
      "2 -> 144 -> 275 -> 363 -> 230 -> 328 -> 226\n",
      "265 -> 346 -> 223 -> 388\n",
      "102 -> 288 -> 38 -> 317 -> 23 -> 26 -> 353 -> 204 -> 335\n",
      "181 -> 368 -> 152 -> 185 -> 334 -> 168 -> 241 -> 318 -> 220 -> 342 -> 219 -> 203 -> 283\n",
      "232 -> 81 -> 171 -> 99 -> 104 -> 333 -> 47 -> 302 -> 37 -> 88 -> 40 -> 265\n",
      "327 -> 122 -> 348 -> 192 -> 299 -> 287 -> 385 -> 48 -> 322 -> 146 -> 271\n",
      "278 -> 206 -> 357 -> 52 -> 229 -> 314 -> 66 -> 42 -> 205 -> 392 -> 310 -> 101 -> 123\n",
      "305 -> 169 -> 22 -> 266 -> 11 -> 397 -> 235 -> 109 -> 258 -> 55 -> 145 -> 128 -> 347 -> 247 -> 51 -> 278\n",
      "271 -> 80 -> 58 -> 343 -> 111 -> 374 -> 259 -> 273 -> 137 -> 136 -> 156\n",
      "388 -> 215 -> 106 -> 381 -> 218 -> 289 -> 183 -> 115 -> 376 -> 285 -> 130 -> 222 -> 148 -> 176 -> 2\n",
      "308 -> 321 -> 239 -> 221 -> 251 -> 100 -> 78 -> 17 -> 293 -> 370 -> 141 -> 147 -> 103\n",
      "369 -> 94 -> 208 -> 364 -> 75 -> 56 -> 210 -> 53 -> 329 -> 396 -> 154 -> 339 -> 217 -> 36 -> 393 -> 336 -> 102\n",
      "248 -> 256 -> 126 -> 292 -> 362 -> 82 -> 92 -> 174 -> 62 -> 16 -> 390 -> 246 -> 211 -> 391 -> 378\n",
      "156 -> 255 -> 366 -> 120 -> 384 -> 264 -> 361 -> 6 -> 125 -> 191 -> 284 -> 359 -> 308\n",
      "216 -> 9 -> 84 -> 29 -> 129 -> 63 -> 138 -> 190 -> 86 -> 286 -> 139 -> 95 -> 83 -> 60 -> 164 -> 257 -> 304 -> 59\n",
      "4 -> 240 -> 243 -> 161 -> 177 -> 252 -> 301 -> 355 -> 90 -> 65 -> 282 -> 20 -> 250 -> 74 -> 41 -> 61 -> 319 -> 312\n",
      "323 -> 77 -> 200 -> 354 -> 14 -> 307 -> 209 -> 131 -> 236 -> 349 -> 260 -> 50 -> 91 -> 76 -> 214 -> 142 -> 30 -> 193 -> 387 -> 173\n",
      "325 -> 79 -> 351 -> 72 -> 175 -> 270 -> 97 -> 39 -> 167 -> 15 -> 179 -> 375 -> 187 -> 274 -> 3 -> 143 -> 7 -> 263 -> 232\n",
      "196 -> 225 -> 124 -> 202 -> 45 -> 389 -> 262 -> 341 -> 199 -> 261 -> 372 -> 398 -> 303 -> 253 -> 135 -> 71 -> 158 -> 300 -> 194 -> 382 -> 196\n",
      "32 -> 367 -> 320 -> 172 -> 297 -> 64 -> 54 -> 180 -> 365 -> 371 -> 116 -> 107 -> 5 -> 279 -> 162 -> 324 -> 207 -> 89 -> 34 -> 43 -> 32\n",
      "25 -> 112 -> 296 -> 373 -> 87 -> 117 -> 165 -> 277 -> 228 -> 379 -> 149 -> 290 -> 184 -> 108 -> 238 -> 12 -> 267 -> 113 -> 233 -> 231 -> 25\n",
      "178 -> 330 -> 69 -> 276 -> 380 -> 46 -> 35 -> 140 -> 57 -> 182 -> 31 -> 118 -> 399 -> 245 -> 291 -> 295 -> 269 -> 85 -> 73 -> 213 -> 178\n",
      "234 -> 157 -> 272 -> 281 -> 350 -> 311 -> 188 -> 224 -> 340 -> 44 -> 114 -> 268 -> 24 -> 10 -> 345 -> 306 -> 377 -> 8 -> 331 -> 337 -> 234\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "            \n",
    "def make_graph(filename):\n",
    "    graph = defaultdict(int)\n",
    "    in_count = defaultdict(int)\n",
    "    out_count = defaultdict(int)\n",
    "    with open(filename) as fp:\n",
    "        lines = fp.readlines()\n",
    "        lines = [line.strip().split(' -> ') for line in lines]\n",
    "    for line in lines:\n",
    "        graph[line[0]] = [line[1]] if len(line[1].split(','))==1 else line[1].split(',')\n",
    "    \n",
    "    for node, neighbors in graph.items():\n",
    "        out_count[node] = len(neighbors)\n",
    "        for neigbor in neighbors:\n",
    "            in_count[neigbor] += 1\n",
    "            \n",
    "    return graph, in_count, out_count\n",
    "\n",
    "def find_balance_and_imbalance(in_count, out_count):\n",
    "    balance_nodes = []\n",
    "    imbalance_nodes = []\n",
    "    for node in set(list(in_count.keys()) + list(out_count.keys())):\n",
    "        if in_count[node]==1 and out_count[node]==1:\n",
    "            balance_nodes.append(node)\n",
    "        else:\n",
    "            imbalance_nodes.append(node)\n",
    "    \n",
    "    return balance_nodes, imbalance_nodes\n",
    "\n",
    "def find_start_and_end(in_count, out_count, imbalance_nodes):\n",
    "    start_nodes = []\n",
    "    end_nodes = []\n",
    "    for imbalance_node in imbalance_nodes:\n",
    "        if out_count[imbalance_node] != 0:\n",
    "            start_nodes.append(imbalance_node)\n",
    "            \n",
    "        if in_count[imbalance_node] != 0:\n",
    "            end_nodes.append(imbalance_node)\n",
    "    \n",
    "    return start_nodes, end_nodes\n",
    "\n",
    "def iter_balance_node(balance_node, balance_nodes, graph):\n",
    "    path = [balance_node]\n",
    "    while True:\n",
    "        if graph[path[-1]][0] in balance_nodes and (path[-1] != path[0] or len(path) == 1):\n",
    "            path.append(graph[path[-1]][0])\n",
    "        else:\n",
    "            break\n",
    "    if path[-1] == path[0] and len(path) != 1:\n",
    "        return path\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "def iter_path(paths ,all_result, balance_nodes, end_nodes, graph):\n",
    "    for path in paths:\n",
    "        for value in graph[path[-1]]:\n",
    "            if value in balance_nodes:\n",
    "                paths.append(path + [value])\n",
    "            elif value in end_nodes:\n",
    "                all_result.append(path + [value])\n",
    "        paths.remove(path)\n",
    "    return paths, all_result\n",
    "    \n",
    "def iter(start_nodes, balance_nodes, end_nodes, graph):\n",
    "    paths = [[start_node] for start_node in start_nodes]\n",
    "    all_result = []\n",
    "    while len(paths) != 0:\n",
    "        paths, all_result = iter_path(paths, all_result, balance_nodes, end_nodes, graph)\n",
    "    \n",
    "    return all_result\n",
    "\n",
    "def get_config(results):\n",
    "    results_seq =  []\n",
    "    for result in results:\n",
    "        results_seq.append(''.join([result[i][:] if i==0 else result[i][-1] for i in range(len(result))]))\n",
    "    return results_seq\n",
    "\n",
    "\n",
    "graph, in_count, out_count = make_graph('rosalind_ba3m.txt')\n",
    "\n",
    "balance_nodes, imbalance_nodes = find_balance_and_imbalance(in_count, out_count)\n",
    "\n",
    "cycle_results = []\n",
    "\n",
    "for balance_node in balance_nodes:\n",
    "    cycle_results.append(iter_balance_node(balance_node, balance_nodes, graph))\n",
    "\n",
    "cycle_results = [x for x in cycle_results if x != None]\n",
    "\n",
    "def equal_list(list1, list2):\n",
    "    list1 = list1[:-1]\n",
    "    list2 = list2[:-1]\n",
    "    if set(list1) == set(list2):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "cycle_results_new = [cycle_results[0]]\n",
    "for i in range(1, len(cycle_results)):\n",
    "    flag = 0\n",
    "    for item in cycle_results_new:\n",
    "        if equal_list(item, cycle_results[i]):\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag == 0:\n",
    "        cycle_results_new.append(cycle_results[i])\n",
    "    \n",
    "    \n",
    "start_nodes, end_nodes = find_start_and_end(in_count, out_count, imbalance_nodes)\n",
    "results = iter(start_nodes, balance_nodes, end_nodes, graph) + cycle_results_new\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    print(' -> '.join(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
